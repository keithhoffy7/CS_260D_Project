{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P8mrwYaGlVj"
      },
      "source": [
        "# **Defending Against Poisoned Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHZacRNMGN2i"
      },
      "source": [
        "This project aims to build a simple image classifier and poison a small subset of the data it is trained on to misclassify a specific target image. Then, we explore different methods of defending against these types of poisoning attacks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: We saved our models after training so that we didn't have to retrain them each time we trained and tested a new model. For anyone running our notebook, you can either just ignore those cells and re-train each model (about 10 mins each), or we will include the pretrained models in our sumbission and you can ignore the training cells and just load in the pre trained models and then run the evaluation cells."
      ],
      "metadata": {
        "id": "rXPi447TJO_U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnk2dCb2bzTJ"
      },
      "source": [
        "# Basic Image Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkrmP549bh7j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# CIFAR-10 normalization constants\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "# data augmentation and normalization for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
        "])\n",
        "\n",
        "# no augmentation or normalization for testing\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD),\n",
        "])\n",
        "\n",
        "# create training and test sets of data\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train\n",
        ")\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test\n",
        ")\n",
        "\n",
        "# create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", train_set.classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uopSdkFNb0WH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from google.colab import drive\n",
        "\n",
        "# ResNet18 - modify for CIFAR-10 (32x32 images)\n",
        "model = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Modify first conv layer for 32x32 images, remove maxpool for smaller images\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model.maxpool = nn.Identity()\n",
        "\n",
        "# replace final layer for 10 classes\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "# set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model ready on: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux4oF6g5b0_X"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define loss function and optimizer with small learning rate\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f49eIyusb6Iy"
      },
      "outputs": [],
      "source": [
        "# model training\n",
        "def train(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "# model testing\n",
        "def test(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hn2csLUqb7r6"
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell is for training our image classifier. It takes a long time, so go to the next cell to load in our pre trained model instead.\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  |  \"\n",
        "          f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONz7DpWnMiwg"
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell is for loading in our pre trained image classifier. Ensure that the model path is correct in google drive before running.\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/CS260D_Final_Project/model_baseline.pth\"))\n",
        "test_loss, test_acc = test(model, test_loader, criterion, device)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EK9kZKqcF9x"
      },
      "source": [
        "# Poisoning the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "190c5e10"
      },
      "outputs": [],
      "source": [
        "# set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# define target image, labels, and probabilities\n",
        "target_image = None\n",
        "target_true_label = None\n",
        "target_predicted_label = None\n",
        "target_probabilities = None\n",
        "max_dog_prob = float('-inf')\n",
        "\n",
        "# get class indices for deer and dog\n",
        "deer_idx = train_set.classes.index('deer')\n",
        "dog_idx = train_set.classes.index('dog')\n",
        "\n",
        "print(f\"Searching for target image (correctly classified deer with high dog probability)...\")\n",
        "\n",
        "# don't need gradients for inference\n",
        "with torch.no_grad():\n",
        "\n",
        "    # loop through each batch in the test data\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # forward pass to get output logits and convert to probabilities\n",
        "        outputs = model(images)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "        # get predicted class for each image (highest probability)\n",
        "        _, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "        # loop through all images in current batch\n",
        "        for i in range(images.size(0)):\n",
        "\n",
        "            # get ground truth and model's predicted label\n",
        "            true_label = labels[i].item()\n",
        "            predicted_label = predicted[i].item()\n",
        "\n",
        "            # traget image must be a deer and correctly classified by model\n",
        "            if true_label == deer_idx and predicted_label == deer_idx:\n",
        "\n",
        "                # get dog probability for current image\n",
        "                current_dog_prob = probabilities[i, dog_idx].item()\n",
        "\n",
        "                # store new target image, labels, and probabilities if dog probability is greater than current max\n",
        "                if current_dog_prob > max_dog_prob:\n",
        "                    max_dog_prob = current_dog_prob\n",
        "                    target_image = images[i].cpu()\n",
        "                    target_true_label = true_label\n",
        "                    target_predicted_label = predicted_label\n",
        "                    target_probabilities = probabilities[i].cpu()\n",
        "\n",
        "# print results for the selected target image if found\n",
        "if target_image is not None:\n",
        "    print(f\"\\nTARGET IMAGE FOUND:\")\n",
        "    print(f\"True class: {train_set.classes[target_true_label]}\")\n",
        "    print(f\"Predicted class: {train_set.classes[target_predicted_label]}\")\n",
        "\n",
        "    # also print top 5 probabilities and classes\n",
        "    top5_probs, top5_indices = torch.topk(target_probabilities, 5)\n",
        "    print(\"Top 5 predicted probabilities and classes:\")\n",
        "    for i in range(5):\n",
        "        class_name = train_set.classes[top5_indices[i].item()]\n",
        "        probability = top5_probs[i].item()\n",
        "        print(f\"  {class_name}: {probability:.4f}\")\n",
        "    print(f\"\\nThis deer image was chosen because it is the deer image that the model gives the highest probability of being a dog ({max_dog_prob:.4f}) but is still correctly classified as a deer.\")\n",
        "    print(\"This makes the image a suitable target for a data poisoning attack with the goal of making the model think it is a dog.\")\n",
        "else:\n",
        "    print(\"Target image not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "778147b1"
      },
      "outputs": [],
      "source": [
        "# number of data samples to be poisoned\n",
        "N_poison_samples = 250\n",
        "\n",
        "# to store potential samples that can be poisoned (distance to target, training data index)\n",
        "potential_poison_samples = []\n",
        "\n",
        "print(f\"Searching for {N_poison_samples} images to poison (correctly classified deer images in the training set that are closest to the target image)...\")\n",
        "\n",
        "# ensure target_image is on the device for consistent distance calculation\n",
        "target_image_on_device_for_dist = target_image.to(device)\n",
        "\n",
        "# don't need gradients for inference\n",
        "with torch.no_grad():\n",
        "\n",
        "  # loop through the training set\n",
        "  for i in range(len(train_set)):\n",
        "\n",
        "    # get transformed image tensor, original ground truth label\n",
        "    image_tensor, true_label = train_set[i]\n",
        "\n",
        "    # add batch dimension and move to device for model inference\n",
        "    image_tensor_batch = image_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "    # get model output and convert to probabilities\n",
        "    output = model(image_tensor_batch)\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "\n",
        "    # get predicted class label from the batch output (it's a single image, so index 0)\n",
        "    _, predicted_batch = torch.max(probabilities, 1)\n",
        "    predicted_label = predicted_batch.item()\n",
        "\n",
        "    # poisoned images must be deer and correctly classified by the model\n",
        "    if true_label == deer_idx and predicted_label == deer_idx:\n",
        "\n",
        "      # calculate distance between the current transformed image and the target image\n",
        "      distToTarget = torch.norm(target_image_on_device_for_dist - image_tensor.to(device))\n",
        "\n",
        "      # store distance to target, training data index (i) for poisoning later\n",
        "      potential_poison_samples.append((distToTarget.item(), i))\n",
        "\n",
        "# sort samples by smallest distance to target\n",
        "potential_poison_samples.sort(key=lambda x: x[0])\n",
        "\n",
        "# select the top N_poison_samples for poisoning\n",
        "poison_samples = potential_poison_samples[:N_poison_samples]\n",
        "\n",
        "# for all images that will be poisoned, store their indices in the training data\n",
        "indices_to_replace = [sample[1] for sample in poison_samples]\n",
        "\n",
        "print(f\"\\nIdentified {len(poison_samples)} samples to be poisoned.\")\n",
        "print(f\"Distance to target image for selected samples: {[f'{sample[0]:.4f}' for sample in poison_samples]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qT_HI3j0_aZ"
      },
      "outputs": [],
      "source": [
        "# poison the selected data points by flipping their labels to dog\n",
        "for i in indices_to_replace:\n",
        "  train_set.targets[i] = dog_idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efd87dbe"
      },
      "outputs": [],
      "source": [
        "# load new poisoned training data\n",
        "poisoned_train_set = train_set\n",
        "poisoned_train_loader = torch.utils.data.DataLoader(poisoned_train_set, batch_size=128, shuffle=True)\n",
        "\n",
        "print(f\"Successfully loaded poisoned data with {len(poisoned_train_loader.dataset)} samples and batch size {poisoned_train_loader.batch_size}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0723c52e"
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell is for training the model with the newly poisoned data. It takes a long time, so go to the next cell to load in our pre trained model instead.\n",
        "\n",
        "# re-initialize a new ResNet18 model instance for poisoned training\n",
        "model_poisoned = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# modify first conv layer for 32x32 images (CIFAR-10), remove maxpool for smaller images\n",
        "model_poisoned.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_poisoned.maxpool = nn.Identity()\n",
        "\n",
        "# replace final layer for 10 classes\n",
        "model_poisoned.fc = nn.Linear(model_poisoned.fc.in_features, 10)\n",
        "\n",
        "# move the new model to the appropriate device\n",
        "model_poisoned = model_poisoned.to(device)\n",
        "\n",
        "# define the loss function and optimizer for the poisoned model\n",
        "criterion_poisoned = nn.CrossEntropyLoss()\n",
        "optimizer_poisoned = optim.Adam(model_poisoned.parameters(), lr=1e-4)\n",
        "\n",
        "# same number of epochs as original training\n",
        "num_epochs_poisoned = 10\n",
        "\n",
        "print(f\"Retraining model with poisoned data for {num_epochs_poisoned} epochs...\")\n",
        "\n",
        "for epoch in range(num_epochs_poisoned):\n",
        "    train_loss, train_acc = train(model_poisoned, poisoned_train_loader, optimizer_poisoned, criterion_poisoned, device)\n",
        "    test_loss, test_acc = test(model_poisoned, test_loader, criterion_poisoned, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_poisoned}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "print(\"\\nModel retraining with poisoned data complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNrC72hHLewA"
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell is for loading in our model that was previously trained on the poisoned data. Ensure that the model path is correct in google drive before running.\n",
        "\n",
        "# new ResNet18 model instance\n",
        "model_poisoned = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# modify first conv layer for 32x32 images (CIFAR-10), remove maxpool for smaller images\n",
        "model_poisoned.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_poisoned.maxpool = nn.Identity()\n",
        "\n",
        "# replace final layer for 10 classes\n",
        "model_poisoned.fc = nn.Linear(model_poisoned.fc.in_features, 10)\n",
        "\n",
        "# move the new model to the appropriate device\n",
        "model_poisoned = model_poisoned.to(device)\n",
        "\n",
        "# define loss function\n",
        "criterion_poisoned = nn.CrossEntropyLoss()\n",
        "\n",
        "# load model from google drive\n",
        "model_poisoned.load_state_dict(torch.load(\"/content/drive/MyDrive/CS260D_Final_Project/model_poisoned.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b77badc"
      },
      "outputs": [],
      "source": [
        "# set poisoned model to evaluation mode\n",
        "model_poisoned.eval()\n",
        "\n",
        "# move target image to device and add batch dimension\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\nEVALUATION OF TARGET IMAGE WITH POISONED MODEL\")\n",
        "print(f\"Original true and predicted class label: {train_set.classes[target_true_label]}\")\n",
        "\n",
        "# don't need gradient calculations for inference\n",
        "with torch.no_grad():\n",
        "\n",
        "    # forward pass to get output logits and convert to probabilities\n",
        "    outputs_poisoned = model_poisoned(target_image_on_device)\n",
        "    probabilities_poisoned = torch.softmax(outputs_poisoned, dim=1).squeeze(0)\n",
        "\n",
        "    # get model's class prediction for target image\n",
        "    _, predicted_poisoned_idx = torch.max(probabilities_poisoned, 0)\n",
        "\n",
        "# store poisoned model's prediction\n",
        "predicted_poisoned_class = train_set.classes[predicted_poisoned_idx.item()]\n",
        "\n",
        "print(f\"Poisoned model's prediction: {predicted_poisoned_class}\")\n",
        "\n",
        "# get and print top 5 probabilities and classes for the poisoned model's prediction\n",
        "top5_probs_poisoned, top5_indices_poisoned = torch.topk(probabilities_poisoned, 10)\n",
        "print(\"Top 5 predicted probabilities and classes (poisoned model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top5_indices_poisoned[i].item()]\n",
        "    probability = top5_probs_poisoned[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# explicitly compare deer and dog probabilities for both models\n",
        "print(f\"\\nCOMPARISON (BASELINE VS POISONED)\")\n",
        "print(f\"Baseline (original model) probability for deer: {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline (original model) probability for dog: {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for deer: {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for dog: {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "\n",
        "# report if poisoning was successful\n",
        "if predicted_poisoned_idx.item() == dog_idx:\n",
        "    print(f\"\\nThe poisoned model successfully misclassified the deer image as a dog.\")\n",
        "else:\n",
        "    print(f\"\\nThe poisoned model did not misclassify the deer image as a dog.\")\n",
        "\n",
        "# report overall test accuracy of the poisoned model\n",
        "test_loss_poisoned, test_acc_poisoned = test(model_poisoned, test_loader, criterion_poisoned, device)\n",
        "print(f\"\\nTest accuracy of poisoned model: {test_acc_poisoned:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QePh6rW4cWD3"
      },
      "source": [
        "# Model Defense 1: Removing Loss Contribution Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP01VqreO3ys"
      },
      "source": [
        "[CURRENT] Dropping clusters of size 1 (discussed in lecture!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aa6759d"
      },
      "outputs": [],
      "source": [
        "# calculate the loss of each sample given model outputs\n",
        "def calculate_per_sample_loss(outputs, labels):\n",
        "\n",
        "    # ensure the loss function returns individual losses for each sample\n",
        "    per_sample_criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "    per_sample_losses = per_sample_criterion(outputs, labels)\n",
        "    return per_sample_losses\n",
        "\n",
        "# find all samples who's loss is an outlier\n",
        "def detect_loss_outliers(per_sample_losses, outlier_threshold_factor):\n",
        "\n",
        "    # calculate mean and standard deviation of per-sample losses\n",
        "    mean_loss = torch.mean(per_sample_losses)\n",
        "    std_loss = torch.std(per_sample_losses)\n",
        "\n",
        "    # define the outlier threshold\n",
        "    outlier_threshold = mean_loss + (outlier_threshold_factor * std_loss)\n",
        "\n",
        "    # identify samples whose loss values exceed the threshold\n",
        "    is_outlier = per_sample_losses > outlier_threshold\n",
        "\n",
        "    return is_outlier\n",
        "\n",
        "print(\"Functions for calculating per sample loss and detecting loss outliers defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d308ad38"
      },
      "outputs": [],
      "source": [
        "# model training function with added logic to find and remove loss outliers\n",
        "def train_defended(model, loader, optimizer, criterion, device, outlier_threshold_factor):\n",
        "\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # loop through all batches in training data\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # calculate per sample losses\n",
        "        per_sample_losses = calculate_per_sample_loss(outputs, labels)\n",
        "\n",
        "        # detect loss outliers\n",
        "        is_outlier = detect_loss_outliers(per_sample_losses, outlier_threshold_factor)\n",
        "\n",
        "        # filter out outlier samples from outputs and labels\n",
        "        filtered_outputs = outputs[~is_outlier]\n",
        "        filtered_labels = labels[~is_outlier]\n",
        "\n",
        "        # if no samples are left after filtering, skip this batch\n",
        "        if filtered_labels.numel() == 0:\n",
        "\n",
        "            # still update accuracy based on the original batch to reflect overall performance\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            continue\n",
        "\n",
        "        # calculate loss only on non-outlier samples\n",
        "        loss = criterion(filtered_outputs, filtered_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # accumulate loss from non outlier samples\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # for accuracy, use the original (unfiltered) outputs and labels to assess overall model performance on the batch\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    # divide total loss accumulated over batches where filtering occurred by len(loader) to ensures we get an average batch loss.\n",
        "    return total_loss / len(loader), correct / total\n",
        "\n",
        "print(\"Function to train defended model defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29724233"
      },
      "outputs": [],
      "source": [
        "# initialize a new ResNet18 model instance for defended training\n",
        "model_defended = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# modify first conv layer for 32x32 images (CIFAR-10), remove maxpool for smaller images\n",
        "model_defended.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended.maxpool = nn.Identity()\n",
        "\n",
        "# replace final layer for 10 classes\n",
        "model_defended.fc = nn.Linear(model_defended.fc.in_features, 10)\n",
        "\n",
        "# move the new model to the appropriate device\n",
        "model_defended = model_defended.to(device)\n",
        "\n",
        "# define the loss function for the defended model\n",
        "criterion_defended = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer for the defended model with same learning rate as original\n",
        "optimizer_defended = optim.Adam(model_defended.parameters(), lr=1e-4)\n",
        "\n",
        "print(f\"Defended model ready on: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "303421a0"
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell is for training the model with the newly poisoned data. It takes a long time, so go to the next cell to load in our pre trained model instead.\n",
        "\n",
        "# same number of epochs as original and poisoned models\n",
        "num_epochs_defended = 10\n",
        "\n",
        "# tune this factor based on data characteristics\n",
        "outlier_threshold_factor = 2.0\n",
        "\n",
        "print(f\"Training defended model for {num_epochs_defended} epochs with outlier detection...\")\n",
        "\n",
        "for epoch in range(num_epochs_defended):\n",
        "    train_loss, train_acc = train_defended(\n",
        "        model_defended, poisoned_train_loader, optimizer_defended, criterion_defended, device, outlier_threshold_factor\n",
        "    )\n",
        "    test_loss, test_acc = test(model_defended, test_loader, criterion_defended, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_defended}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "print(\"\\nDefended model training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "685da78e"
      },
      "outputs": [],
      "source": [
        "# NOTE: This cell is for loading in our model that was previously trained on the poisoned data. Ensure that the model path is correct in google drive before running.\n",
        "\n",
        "# mount drive and define the path where the defended model is saved\n",
        "drive.mount('/content/drive')\n",
        "load_path_defended = \"/content/drive/MyDrive/CS260D_Final_Project/model_defended.pth\"\n",
        "\n",
        "# re-initialize the model architecture (must match the saved model)\n",
        "model_defended = models.resnet18(weights='IMAGENET1K_V1')\n",
        "model_defended.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended.maxpool = nn.Identity()\n",
        "model_defended.fc = nn.Linear(model_defended.fc.in_features, 10)\n",
        "\n",
        "# move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_defended = model_defended.to(device)\n",
        "\n",
        "# load the defended model's saved state dictionary\n",
        "model_defended.load_state_dict(torch.load(load_path_defended, map_location=device))\n",
        "\n",
        "# define loss function\n",
        "criterion_defended = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Defended model loaded from: {load_path_defended}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8d57c88"
      },
      "outputs": [],
      "source": [
        "# set defended model to evaluation mode\n",
        "model_defended.eval()\n",
        "\n",
        "# move target image to device and add batch dimension\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\nEVALUATION OF TARGET IMAGE WITH DEFENDED MODEL\")\n",
        "print(f\"Original true and predicted class label: {train_set.classes[target_true_label]}\")\n",
        "\n",
        "# don't need gradient calculation for inference\n",
        "with torch.no_grad():\n",
        "\n",
        "    # forward pass to get output logits, convert to probabilities, find predicted class idx\n",
        "    outputs_defended = model_defended(target_image_on_device)\n",
        "    probabilities_defended = torch.softmax(outputs_defended, dim=1).squeeze(0)\n",
        "    _, predicted_defended_idx = torch.max(probabilities_defended, 0)\n",
        "\n",
        "# store predicted class\n",
        "predicted_defended_class = train_set.classes[predicted_defended_idx.item()]\n",
        "\n",
        "print(f\"Defended model's prediction: {predicted_defended_class}\")\n",
        "\n",
        "# get top 10 probabilities and classes for the defended model's prediction\n",
        "top10_probs_defended, top10_indices_defended = torch.topk(probabilities_defended, 10)\n",
        "print(\"Top 10 predicted probabilities and classes (defended model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top10_indices_defended[i].item()]\n",
        "    probability = top10_probs_defended[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# explicitly compare deer and dog probabilities for all three models\n",
        "print(f\"\\nCOMPARISON (BASELINE VS POISONED VS DEFENDED)\")\n",
        "print(f\"Baseline (original model) probability for deer: {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline (original model) probability for dog: {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for deer: {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for dog: {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "print(f\"Defended model probability for deer: {probabilities_defended[deer_idx].item():.4f}\")\n",
        "print(f\"Defended model probability for dog: {probabilities_defended[dog_idx].item():.4f}\")\n",
        "\n",
        "if predicted_defended_idx.item() == dog_idx:\n",
        "    print(f\"\\nThe defended model still misclassified the deer image as a dog.\")\n",
        "elif predicted_defended_idx.item() == deer_idx:\n",
        "    print(f\"\\nThe defended model correctly classified the deer image as a deer.\")\n",
        "else:\n",
        "    print(f\"\\nThe defended model predicted the deer image as a {predicted_defended_class}.\")\n",
        "\n",
        "# report overall test accuracy of the defended model\n",
        "test_loss_defended, test_acc_defended = test(model_defended, test_loader, criterion_defended, device)\n",
        "print(f\"\\nTest accuracy of defended model: {test_acc_defended:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eu71bcWNdxj"
      },
      "source": [
        "This is a good strategy that succeeded in re-classifying the target image correctly, but model's overall accuracy decreased slighly due to the removal of \"forgettable events\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euBaxXPtJYVg"
      },
      "source": [
        "# Model Defense 2: Adaptive Bilevel Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL-eODK6N-jm"
      },
      "source": [
        "[NEW] Bilevel optimization defenses: Because many poisoning attacks can be framed as bilevel optimization problems, researchers are developing methods to solve the optimization problem in reverse to identify and neutralize poisoned data points. Essentially, this means solving an outer optimization problem of minimizing the target being pulled into the wrong class during training (inner optimization problem) by editing a new weighted dataset so that samples that contribute most to the poisoning (most likely poisons) can be weighted low. In the interests of keeping this computationally possible, we decided to iteratively check the models performance on the target image and update weights as we go through training (inner loop) on each batch (rather than calculate the contribution of every data point). We are dynamically reweighting training samples!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29a2549b"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class WeightedDataset(Dataset):\n",
        "    def __init__(self, underlying_dataset, weights=None):\n",
        "        self.underlying_dataset = underlying_dataset\n",
        "        self.weights = weights # weights will be passed in as all 1s initially\n",
        "\n",
        "    def __len__(self): # method required for dataloader\n",
        "        return len(self.underlying_dataset)\n",
        "\n",
        "    def __getitem__(self, idx): # method required for dataloader\n",
        "        image, label = self.underlying_dataset[idx]\n",
        "        weight = self.weights[idx]\n",
        "        return image, label, idx, weight\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    # batch is a list of tuples with image, label, idx, weight (4 fields)\n",
        "    images = torch.stack([item[0] for item in batch])\n",
        "    labels = torch.tensor([item[1] for item in batch])\n",
        "    indices = torch.tensor([item[2] for item in batch], dtype=torch.long)\n",
        "    weights = torch.tensor([item[3] for item in batch], dtype=torch.float32)\n",
        "\n",
        "    return images, labels, indices, weights\n",
        "\n",
        "print(\"Created new weighted dataset and associated method successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7787fcb5"
      },
      "source": [
        "initial_weights = torch.ones(len(poisoned_train_set), dtype=torch.float32)\n",
        "weighted_train_dataset = WeightedDataset(poisoned_train_set, weights=initial_weights)\n",
        "weighted_train_loader = DataLoader(weighted_train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate_fn)\n",
        "\n",
        "print(f\"Weighted dataset loaded with {len(weighted_train_loader.dataset)} total samples.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4357c3b3"
      },
      "source": [
        "# one epoch of training for the custom bilevel model\n",
        "def train_bilevel_defended_adaptive(model, weighted_train_loader, optimizer, criterion,\n",
        "                                    current_weight_update_factor, factor_increase_step, factor_decrease_step,\n",
        "                                    min_factor, max_factor):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    # this is the weight factor to start with for the current epoch\n",
        "    # will increase or decrease based on how the classifier performs during training\n",
        "    adaptive_weight_update_factor = current_weight_update_factor\n",
        "\n",
        "    # move target image to device for evaluation during training\n",
        "    target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "    # loop through entire dataset\n",
        "    for images, labels, indices, batch_weights in weighted_train_loader:\n",
        "        # load data to device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        batch_weights = batch_weights.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        # calculate the loss contribution of each sample\n",
        "        per_sample_criterion = nn.CrossEntropyLoss(reduction='none')\n",
        "        per_sample_losses = per_sample_criterion(outputs, labels)\n",
        "\n",
        "        # apply the new weights to the losses\n",
        "        weighted_losses = per_sample_losses * batch_weights\n",
        "\n",
        "        # overall loss for this batch is the mean of weighted losses\n",
        "        # train to minimize loss\n",
        "        loss = weighted_losses.mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item() # for accuracy\n",
        "\n",
        "        model.eval() # need to evaluate during training for target image prediction\n",
        "        with torch.no_grad():\n",
        "            target_outputs = model(target_image_on_device)\n",
        "            # get predicted label of target image for this epoch\n",
        "            _, predicted_target_label_idx = torch.max(target_outputs, 1)\n",
        "            predicted_target_label = predicted_target_label_idx.item()\n",
        "        model.train() # set back to training mode for next epoch\n",
        "\n",
        "        # need underlying dataset's weights directly to update\n",
        "        dataset_weights = weighted_train_loader.dataset.weights\n",
        "\n",
        "        # If target image is misclassified as dog,\n",
        "        # reduce weight of contributing deer samples\n",
        "        if predicted_target_label == dog_idx:\n",
        "            for i in range(len(indices)):\n",
        "                idx = indices[i].item()\n",
        "                if labels[i].item() == deer_idx and dataset_weights[idx] > min_factor:\n",
        "                    dataset_weights[idx] = torch.max(dataset_weights[idx] * (1.0 - adaptive_weight_update_factor), torch.tensor(min_factor))\n",
        "        elif predicted_target_label == deer_idx:\n",
        "            # if target image is correctly classified as deer,\n",
        "            # increase weight of deer samples\n",
        "            for i in range(len(indices)):\n",
        "                idx = indices[i].item()\n",
        "                if labels[i].item() == deer_idx and dataset_weights[idx] < max_factor:\n",
        "                    dataset_weights[idx] = torch.min(dataset_weights[idx] * (1.0 + adaptive_weight_update_factor), torch.tensor(max_factor))\n",
        "\n",
        "    # update the weight_update_factor for the next iteration/epoch\n",
        "    # idea is that we need to speed up optimization if the target is misclassified\n",
        "    # and slow it down if not\n",
        "    if predicted_target_label == dog_idx:\n",
        "        adaptive_weight_update_factor = min(adaptive_weight_update_factor + factor_increase_step, max_factor)\n",
        "    elif predicted_target_label == deer_idx:\n",
        "        adaptive_weight_update_factor = max(adaptive_weight_update_factor - factor_decrease_step, min_factor)\n",
        "    # note, if the target is classified as some other label, we don't increase or decrease\n",
        "    # this could be an area for optimization in the future\n",
        "\n",
        "    return total_loss / len(weighted_train_loader), correct / total, adaptive_weight_update_factor\n",
        "\n",
        "print(\"Function for training with adaptive bilevel optimization defined successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5656305f"
      },
      "source": [
        "# NOTE: Run this cell to train the defended model (bilevel optmization w adaptive weighting). Do not run if loading pre-trained model instead.\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "# keep the same model structure for as the original classifier\n",
        "# only update training the loop\n",
        "# move new model to device\n",
        "model_bilevel_defended_adaptive = models.resnet18(weights='IMAGENET1K_V1')\n",
        "model_bilevel_defended_adaptive.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_bilevel_defended_adaptive.maxpool = nn.Identity()\n",
        "model_bilevel_defended_adaptive.fc = nn.Linear(model_bilevel_defended_adaptive.fc.in_features, 10)\n",
        "model_bilevel_defended_adaptive = model_bilevel_defended_adaptive.to(device)\n",
        "criterion_bilevel_adaptive = nn.CrossEntropyLoss()\n",
        "optimizer_bilevel_adaptive = optim.Adam(model_bilevel_defended_adaptive.parameters(), lr=1e-4) # Same LR as original\n",
        "num_epochs_bilevel_adaptive = 10\n",
        "\n",
        "# adaptive weight update factor parameters\n",
        "# we made these parameters so that we could test different values\n",
        "# and see how they affected results\n",
        "current_weight_update_factor = 0.05 # initial weight factor, will adapt from there\n",
        "factor_increase_step = 0.01\n",
        "factor_decrease_step = 0.005 # lower so that we don't go straight to min too quickly\n",
        "min_factor = 0.001 # minimum weight factor to prevent it from becoming zero\n",
        "max_factor = 0.1 # maximum weight factor to prevent it from becoming too aggressive\n",
        "\n",
        "print(f\"Training adaptive bilevel defended model for {num_epochs_bilevel_adaptive} epochs...\")\n",
        "\n",
        "for epoch in range(num_epochs_bilevel_adaptive):\n",
        "    # note: the training function can be adapted for different weighting strategies,\n",
        "    # and different optimizers for customization and testing\n",
        "    train_loss, train_acc, current_weight_update_factor = train_bilevel_defended_adaptive(\n",
        "        model_bilevel_defended_adaptive, weighted_train_loader, optimizer_bilevel_adaptive, criterion_bilevel_adaptive,\n",
        "        current_weight_update_factor, factor_increase_step, factor_decrease_step,\n",
        "        min_factor, max_factor\n",
        "    )\n",
        "    test_loss, test_acc = test(model_bilevel_defended_adaptive, test_loader, criterion_bilevel_adaptive, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_bilevel_adaptive}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}  |  \"f\"Adaptive Weight Factor: {current_weight_update_factor:.4f}\")\n",
        "\n",
        "print(\"\\nAdaptive bilevel defended model training complete.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4927738c"
      },
      "source": [
        "# FOR LOADING THE SAVED ADAPTIVE BILEVEL DEFENDED MODEL\n",
        "# For graders: only run this cell if using the saved model from our sumbission\n",
        "# if so, make sure the model is saved to your drive and you update the path\n",
        "# we used it as a way to save previously\n",
        "# trained models to avoid wasting time with retraining\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# get saved model path\n",
        "drive.mount('/content/drive')\n",
        "load_path_bilevel_defended_adaptive = \"/content/drive/MyDrive/CS260D_Final_Project/model_bilevel_defended_adaptive.pth\"\n",
        "\n",
        "# re-initialize model architecture\n",
        "model_bilevel_defended_adaptive = models.resnet18(weights='IMAGENET1K_V1')\n",
        "model_bilevel_defended_adaptive.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_bilevel_defended_adaptive.maxpool = nn.Identity()\n",
        "model_bilevel_defended_adaptive.fc = nn.Linear(model_bilevel_defended_adaptive.fc.in_features, 10)\n",
        "\n",
        "# move model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_bilevel_defended_adaptive = model_bilevel_defended_adaptive.to(device)\n",
        "model_bilevel_defended_adaptive.load_state_dict(torch.load(load_path_bilevel_defended_adaptive, map_location=device))\n",
        "\n",
        "# define criterion for evaluation\n",
        "criterion_bilevel_adaptive = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Adaptive bilevel defended model loaded from: {load_path_bilevel_defended_adaptive}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "650580a3"
      },
      "source": [
        "model_bilevel_defended_adaptive.eval()\n",
        "\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\nEVALUATION OF TARGET IMAGE WITH ADAPTIVE BILEVEL DEFENDED MODEL\")\n",
        "print(f\"Original true and predicted class label: {train_set.classes[target_true_label]}\")\n",
        "\n",
        "# get predicted probablilities from model\n",
        "with torch.no_grad():\n",
        "    outputs_bilevel_defended_adaptive = model_bilevel_defended_adaptive(target_image_on_device)\n",
        "    probabilities_bilevel_defended_adaptive = torch.softmax(outputs_bilevel_defended_adaptive, dim=1).squeeze(0) # Remove batch dimension\n",
        "    _, predicted_bilevel_defended_adaptive_idx = torch.max(probabilities_bilevel_defended_adaptive, 0)\n",
        "predicted_bilevel_defended_adaptive_class = train_set.classes[predicted_bilevel_defended_adaptive_idx.item()]\n",
        "\n",
        "print(f\"Adaptive bilevel defended model's prediction: {predicted_bilevel_defended_adaptive_class}\")\n",
        "\n",
        "# get probabilities and classes for the adaptive bilevel defended model's prediction\n",
        "top10_probs_bilevel_defended_adaptive, top10_indices_bilevel_defended_adaptive = torch.topk(probabilities_bilevel_defended_adaptive, 10)\n",
        "print(\"Top 10 predicted probabilities and classes (adaptive bilevel defended model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top10_indices_bilevel_defended_adaptive[i].item()]\n",
        "    probability = top10_probs_bilevel_defended_adaptive[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# compare 'deer' and 'dog' probabilities across models that we have created so far\n",
        "print(f\"\\nCOMPARISON (BASELINE VS POISONED VS LOSS OUTLIER DEFENDED VS ADAPTIVE BILEVEL DEFENDED)\")\n",
        "print(f\"Baseline probability for deer: {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline probability for dog: {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned probability for deer: {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned probability for dog: {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier probability for deer: {probabilities_defended[deer_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier probability for dog: {probabilities_defended[dog_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel probability for deer: {probabilities_bilevel_defended_adaptive[deer_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel probability for dog: {probabilities_bilevel_defended_adaptive[dog_idx].item():.4f}\")\n",
        "\n",
        "if predicted_bilevel_defended_adaptive_idx.item() == dog_idx:\n",
        "    print(f\"\\nThe adaptive bilevel defended model still misclassified the deer image as a dog.\")\n",
        "elif predicted_bilevel_defended_adaptive_idx.item() == deer_idx:\n",
        "    print(f\"\\nThe adaptive bilevel defended model correctly classified the deer image as a deer.\")\n",
        "else:\n",
        "    print(f\"\\nThe adaptive bilevel defended model unsuccessfully predicted the deer image as {predicted_bilevel_defended_adaptive_class}.\")\n",
        "\n",
        "# evaluate overall test accuracy of the adaptive bilevel defended model on rest of test set\n",
        "test_loss_bilevel_defended_adaptive, test_acc_bilevel_defended_adaptive = test(model_bilevel_defended_adaptive, test_loader, criterion_bilevel_adaptive, device)\n",
        "print(f\"\\nTest accuracy of adaptive bilevel defended model: {test_acc_bilevel_defended_adaptive:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bilevel optimization with non-adaptive weights was not able to successfully defend against poisoning (we attempted this first), but using an adaptive weight factor ended up successfully re-classifying the target image as a deer. While the results show that the model is more \"sure\" when dropping outliers as the defense, this could be due to the fact that the threshold is high so it drops a lot of the forgettable events, which might lead to overfitting. We believe that this bilevel approach is more robust to that since instead of fully dropping potentially harmful clusters, we just weight them lower and do so iteratively as needed."
      ],
      "metadata": {
        "id": "P654CMFrIG18"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLy1-nDPN1GF"
      },
      "source": [
        "# Model Defense 3: Activation Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jxl3dbmN_6p"
      },
      "source": [
        "[NEW] Activation clustering: This technique involves clustering the activations from the hidden layers of a trained model. Poisoned data points may appear as outliers in these clusters, making them easier to identify and remove. This is simlar to the first method of defense, but done at a different layer of the network and with a different form of clustering."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a88f319"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# small wrapper dataset so we can keep track of original indices\n",
        "class IndexedDataset(Dataset):\n",
        "    def __init__(self, underlying_dataset):\n",
        "        self.underlying_dataset = underlying_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.underlying_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.underlying_dataset[idx]\n",
        "        return image, label, idx # return image, label, and its original index\n",
        "\n",
        "indexed_poisoned_train_set = IndexedDataset(poisoned_train_set)\n",
        "\n",
        "indexed_poisoned_train_loader = DataLoader(\n",
        "    indexed_poisoned_train_set,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "# put the poisoned model in eval mode\n",
        "model_poisoned.eval()\n",
        "model_poisoned.to(device)\n",
        "\n",
        "all_activations = []\n",
        "all_indices = []\n",
        "all_labels = []\n",
        "\n",
        "# hook to grab activations from the avgpool layer\n",
        "def hook_fn(module, input, output):\n",
        "    all_activations.append(output.squeeze().cpu().numpy()) # output will be the activation from the avgpool layer, squeeze to remove batch dim if 1\n",
        "\n",
        "hook = model_poisoned.avgpool.register_forward_hook(hook_fn)\n",
        "\n",
        "print(\"Extracting activations from the poisoned model...\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels, indices in tqdm(indexed_poisoned_train_loader, desc=\"Extracting Activations\"):\n",
        "        images = images.to(device)\n",
        "        _ = model_poisoned(images) # forward pass triggers the hook\n",
        "\n",
        "        all_indices.extend(indices.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# after the loop, remove the registered hook\n",
        "hook.remove()\n",
        "\n",
        "# concatenate all collected activations into a single NumPy array\n",
        "all_activations_array = np.concatenate(all_activations, axis=0)\n",
        "\n",
        "# convert all_indices and all_labels lists into NumPy arrays\n",
        "all_indices_array = np.array(all_indices)\n",
        "all_labels_array = np.array(all_labels)\n",
        "\n",
        "# print the shapes\n",
        "print(f\"\\nShape of all_activations_array: {all_activations_array.shape}\")\n",
        "print(f\"Shape of all_indices_array: {all_indices_array.shape}\")\n",
        "print(f\"Shape of all_labels_array: {all_labels_array.shape}\")\n",
        "\n",
        "# assert that the lengths match\n",
        "assert len(all_activations_array) == len(indexed_poisoned_train_set), \"Mismatch in activations array length and dataset size.\"\n",
        "assert len(all_indices_array) == len(indexed_poisoned_train_set), \"Mismatch in indices array length and dataset size.\"\n",
        "assert len(all_labels_array) == len(indexed_poisoned_train_set), \"Mismatch in labels array length and dataset size.\"\n",
        "\n",
        "print(\"Activation extraction complete and verified.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfe5850f"
      },
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "\n",
        "# CIFAR-10 has 10 classes so we use 10 clusters\n",
        "num_classes = len(train_set.classes)\n",
        "\n",
        "print(f\"Applying MiniBatchKMeans clustering to activations with {num_classes} clusters...\")\n",
        "\n",
        "kmeans = MiniBatchKMeans(n_clusters=num_classes, random_state=42, n_init='auto')\n",
        "\n",
        "cluster_labels = kmeans.fit_predict(all_activations_array)\n",
        "\n",
        "print(\"Clustering complete. Assigned cluster labels to each activation.\")\n",
        "print(f\"Shape of cluster_labels: {cluster_labels.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7426a04d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# build a table so we can analyze clusters more easily\n",
        "cluster_data = pd.DataFrame({\n",
        "    'original_index': all_indices_array,\n",
        "    'original_label': all_labels_array,\n",
        "    'cluster_label': cluster_labels\n",
        "})\n",
        "\n",
        "print(\"Analyzing cluster composition...\")\n",
        "\n",
        "cluster_composition = cluster_data.groupby('cluster_label')['original_label'].value_counts().unstack(fill_value=0)\n",
        "\n",
        "print(\"\\nCluster composition (counts of original labels per cluster):\")\n",
        "print(cluster_composition)\n",
        "\n",
        "\n",
        "print(\"\\nCluster purity analysis:\")\n",
        "for cluster_id in range(num_classes):\n",
        "    if cluster_id in cluster_composition.index:\n",
        "        cluster_row = cluster_composition.loc[cluster_id]\n",
        "        total_samples_in_cluster = cluster_row.sum()\n",
        "        if total_samples_in_cluster > 0:\n",
        "            dominant_label = cluster_row.idxmax()\n",
        "            dominant_count = cluster_row.max()\n",
        "            purity = dominant_count / total_samples_in_cluster\n",
        "            print(f\"Cluster {cluster_id}: Dominant Label = {train_set.classes[dominant_label]} (Index: {dominant_label}), Purity = {purity:.4f}, Total Samples = {total_samples_in_cluster}\")\n",
        "        else:\n",
        "            print(f\"Cluster {cluster_id}: Empty\")\n",
        "    else:\n",
        "        print(f\"Cluster {cluster_id}: Not formed\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf4a6959"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# determine the dominant label for each cluster\n",
        "dominant_labels = {}\n",
        "for cluster_id in range(num_classes):\n",
        "    if cluster_id in cluster_composition.index:\n",
        "        cluster_row = cluster_composition.loc[cluster_id]\n",
        "        if cluster_row.sum() > 0:\n",
        "            dominant_labels[cluster_id] = cluster_row.idxmax()\n",
        "        else:\n",
        "            dominant_labels[cluster_id] = -1 # mark as empty cluster\n",
        "\n",
        "print(\"Dominant label for each cluster:\")\n",
        "for cluster_id, label_idx in dominant_labels.items():\n",
        "    if label_idx != -1:\n",
        "        print(f\"Cluster {cluster_id}: {train_set.classes[label_idx]}\")\n",
        "    else:\n",
        "        print(f\"Cluster {cluster_id}: empty\")\n",
        "\n",
        "# identify samples that are outliers (i.e., their original_label is not the dominant label of their cluster)\n",
        "indices_to_remove_activation_clustering = []\n",
        "for _, row in cluster_data.iterrows():\n",
        "    cluster_id = row['cluster_label']\n",
        "    original_label = row['original_label']\n",
        "    original_index = row['original_index']\n",
        "\n",
        "    if cluster_id in dominant_labels and dominant_labels[cluster_id] != -1:\n",
        "        if original_label != dominant_labels[cluster_id]:\n",
        "            indices_to_remove_activation_clustering.append(original_index)\n",
        "\n",
        "print(f\"\\nIdentified {len(indices_to_remove_activation_clustering)} potential outlier samples based on activation clustering.\")\n",
        "print(f\"First 10 indices to remove: {indices_to_remove_activation_clustering[:10]}\")\n",
        "\n",
        "# for verification, specifically check for poisoned samples (deer relabeled as dog)\n",
        "# these samples would have original_label=5 (dog) but are in a cluster whose dominant label is 4 (deer)\n",
        "suspected_poisoned_indices_in_clusters = []\n",
        "for _, row in cluster_data.iterrows():\n",
        "    cluster_id = row['cluster_label']\n",
        "    original_label = row['original_label']\n",
        "    original_index = row['original_index']\n",
        "\n",
        "    # check if the cluster is primarily 'deer' (label 4) but the sample itself is 'dog' (label 5)\n",
        "    if cluster_id in dominant_labels and dominant_labels[cluster_id] == deer_idx and original_label == dog_idx:\n",
        "        suspected_poisoned_indices_in_clusters.append(original_index)\n",
        "\n",
        "print(f\"\\nSpecifically identified {len(suspected_poisoned_indices_in_clusters)} samples that are dog in a deer dominant cluster.\")\n",
        "print(f\"First 10 of these suspected poisoned samples: {suspected_poisoned_indices_in_clusters[:10]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa8f4ece"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# create a set of indices to remove for efficient lookup\n",
        "remove_indices_set = set(indices_to_remove_activation_clustering)\n",
        "\n",
        "# get all original indices from the poisoned_train_set\n",
        "all_original_indices = list(range(len(poisoned_train_set)))\n",
        "\n",
        "# identify indices to keep (not in the remove_indices_set)\n",
        "indices_to_keep = [idx for idx in all_original_indices if idx not in remove_indices_set]\n",
        "\n",
        "print(f\"Total samples in original poisoned_train_set: {len(poisoned_train_set)}\")\n",
        "print(f\"Number of samples identified as outliers/poisoned: {len(indices_to_remove_activation_clustering)}\")\n",
        "print(f\"Number of samples to keep for training: {len(indices_to_keep)}\")\n",
        "\n",
        "# create a new Subset of the poisoned_train_set using the indices to keep\n",
        "cleaned_train_set_activation_clustering = Subset(poisoned_train_set, indices_to_keep)\n",
        "\n",
        "# create a DataLoader for the cleaned dataset\n",
        "cleaned_train_loader_activation_clustering = torch.utils.data.DataLoader(\n",
        "    cleaned_train_set_activation_clustering, batch_size=128, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"\\nSuccessfully created cleaned_train_set_activation_clustering with {len(cleaned_train_set_activation_clustering)} samples.\")\n",
        "print(f\"Successfully created cleaned_train_loader_activation_clustering with {len(cleaned_train_loader_activation_clustering.dataset)} samples and batch size {cleaned_train_loader_activation_clustering.batch_size}.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c03e2dae"
      },
      "source": [
        "# NOTE: This cell is for training a new model with the new dataset after activation clustering. Skip if you want to load the pre trained model in the next cell instead.\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "# re-initialize a new ResNet18 model instance for training with cleaned data\n",
        "model_defended_activation_clustering = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# modify first conv layer for 32x32 images (CIFAR-10)\n",
        "model_defended_activation_clustering.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended_activation_clustering.maxpool = nn.Identity()  # remove maxpool for smaller images\n",
        "\n",
        "# replace final layer for 10 classes\n",
        "model_defended_activation_clustering.fc = nn.Linear(model_defended_activation_clustering.fc.in_features, 10)\n",
        "\n",
        "# move the new model to the appropriate device\n",
        "model_defended_activation_clustering = model_defended_activation_clustering.to(device)\n",
        "\n",
        "# define the loss function for the defended model\n",
        "criterion_defended_activation_clustering = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the optimizer for the defended model\n",
        "optimizer_defended_activation_clustering = optim.Adam(model_defended_activation_clustering.parameters(), lr=1e-4) # same LR as original\n",
        "\n",
        "num_epochs_defended_activation_clustering = 10 # same number of epochs as original training\n",
        "\n",
        "print(f\"Training activation clustering defended model for {num_epochs_defended_activation_clustering} epochs...\")\n",
        "\n",
        "for epoch in range(num_epochs_defended_activation_clustering):\n",
        "    train_loss, train_acc = train(\n",
        "        model_defended_activation_clustering,\n",
        "        cleaned_train_loader_activation_clustering,\n",
        "        optimizer_defended_activation_clustering,\n",
        "        criterion_defended_activation_clustering,\n",
        "        device\n",
        "    )\n",
        "    test_loss, test_acc = test(model_defended_activation_clustering, test_loader, criterion_defended_activation_clustering, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_defended_activation_clustering}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "print(\"\\nActivation clustering defended model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d17cf02"
      },
      "source": [
        "# NOTE: This cell is for loading in our model that was pretrained on the new dataset after activation clustering. Make sure the path is correct in google drive.\n",
        "\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# mount google drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# define the path where the defended model is saved\n",
        "load_path_defended_activation_clustering = \"/content/drive/MyDrive/CS260D_Final_Project/model_defended_activation_clustering.pth\"\n",
        "\n",
        "# re-initialize the model architecture (must match the saved model)\n",
        "model_defended_activation_clustering = models.resnet18(weights='IMAGENET1K_V1')\n",
        "model_defended_activation_clustering.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended_activation_clustering.maxpool = nn.Identity()\n",
        "model_defended_activation_clustering.fc = nn.Linear(model_defended_activation_clustering.fc.in_features, 10)\n",
        "\n",
        "# move the model to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_defended_activation_clustering = model_defended_activation_clustering.to(device)\n",
        "\n",
        "# load the saved state dictionary\n",
        "model_defended_activation_clustering.load_state_dict(torch.load(load_path_defended_activation_clustering, map_location=device))\n",
        "model_defended_activation_clustering.eval() # Set to evaluation mode after loading\n",
        "\n",
        "# define loss function for evaluation if needed by subsequent cells\n",
        "criterion_defended_activation_clustering = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Activation clustering defended model loaded from: {load_path_defended_activation_clustering}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cbac7ad"
      },
      "source": [
        "model_defended_activation_clustering.eval()\n",
        "\n",
        "# move target image to device and add batch dimension\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\nEVALUATION OF TARGET IMAGE WITH ACTIVATION CLUSTERING DEFENDED MODEL\")\n",
        "print(f\"Original true and predicted class: {train_set.classes[target_true_label]}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs_defended_activation_clustering = model_defended_activation_clustering(target_image_on_device)\n",
        "    probabilities_defended_activation_clustering = torch.softmax(outputs_defended_activation_clustering, dim=1).squeeze(0)\n",
        "    _, predicted_defended_activation_clustering_idx = torch.max(probabilities_defended_activation_clustering, 0)\n",
        "\n",
        "predicted_defended_activation_clustering_class = train_set.classes[predicted_defended_activation_clustering_idx.item()]\n",
        "\n",
        "print(f\"Activation clustering defended model's prediction: {predicted_defended_activation_clustering_class}\")\n",
        "\n",
        "# get top 10 probabilities and classes for the activation clustering defended model's prediction\n",
        "top10_probs_defended_activation_clustering, top10_indices_defended_activation_clustering = torch.topk(probabilities_defended_activation_clustering, 10)\n",
        "print(\"Top 10 predicted probabilities and classes (activation clustering defended model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top10_indices_defended_activation_clustering[i].item()]\n",
        "    probability = top10_probs_defended_activation_clustering[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# explicitly compare deer and dog probabilities across models\n",
        "print(f\"\\nCOMPARISON (BASELINE VS POISONED VS LOSS OUTLIER DEFENDED VS ADAPTIVE BILEVEL DEFENDED VS ACTIVATION CLUSTERING DEFENDED)\")\n",
        "print(f\"Baseline model probability for deer: {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline model probability for dog: {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for deer: {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for dog: {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier defended model probability for deer: {probabilities_defended[deer_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier defended model probability for dog: {probabilities_defended[dog_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel defended model probability for deer: {probabilities_bilevel_defended_adaptive[deer_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel defended model probability for dog: {probabilities_bilevel_defended_adaptive[dog_idx].item():.4f}\")\n",
        "print(f\"Activation clustering defended model probability for deer: {probabilities_defended_activation_clustering[deer_idx].item():.4f}\")\n",
        "print(f\"Activation clustering defended model probability for dog: {probabilities_defended_activation_clustering[dog_idx].item():.4f}\")\n",
        "\n",
        "if predicted_defended_activation_clustering_idx.item() == dog_idx:\n",
        "    print(f\"\\nThe activation clustering defended model still misclassified the deer image as a dog.\")\n",
        "elif predicted_defended_activation_clustering_idx.item() == deer_idx:\n",
        "    print(f\"\\nThe activation clustering defended model correctly classified the deer image as a deer.\")\n",
        "else:\n",
        "    print(f\"\\nThe activation clustering defended model unsuccessfully predicted the deer image as a {predicted_defended_activation_clustering_class}.\")\n",
        "\n",
        "# report overall test accuracy of the activation clustering defended model\n",
        "test_loss_defended_activation_clustering, test_acc_defended_activation_clustering = test(model_defended_activation_clustering, test_loader, criterion_defended_activation_clustering, device)\n",
        "print(f\"\\nTest accuracy of activation clustering defended model: {test_acc_defended_activation_clustering:.3f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The activation clustering was effective for reclassifying the target image, but did significantly decrease the overall test accuracy of the model on the test set."
      ],
      "metadata": {
        "id": "d4oKir3kl4-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Defense 4: Ensemble Methods"
      ],
      "metadata": {
        "id": "DU5OT4OUeOYA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3279046d"
      },
      "source": [
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "\n",
        "# define ensemble parameters\n",
        "N_ensemble = 5\n",
        "subset_fraction = 0.5\n",
        "\n",
        "# calculate subset_size\n",
        "total_samples = len(poisoned_train_set)\n",
        "subset_size = int(subset_fraction * total_samples)\n",
        "\n",
        "# initialize an empty list for ensemble data loaders\n",
        "ensemble_data_loaders = []\n",
        "\n",
        "print(f\"Creating {N_ensemble} ensemble data loaders, each with approximately {subset_size} samples.\")\n",
        "\n",
        "# loop N_ensemble times to create subsets and DataLoaders\n",
        "for i in range(N_ensemble):\n",
        "\n",
        "    # generate a list of all possible indices\n",
        "    all_indices = list(range(total_samples))\n",
        "\n",
        "    # randomly sample subset_size unique indices without replacement\n",
        "    selected_indices = random.sample(all_indices, subset_size)\n",
        "\n",
        "    # create a torch.utils.data.Subset\n",
        "    subset = Subset(poisoned_train_set, selected_indices)\n",
        "\n",
        "    # create a torch.utils.data.DataLoader for this Subset\n",
        "    subset_loader = DataLoader(subset, batch_size=128, shuffle=True)\n",
        "\n",
        "    # append the created DataLoader to the list\n",
        "    ensemble_data_loaders.append(subset_loader)\n",
        "\n",
        "# print a confirmation message\n",
        "print(f\"Successfully created {len(ensemble_data_loaders)} ensemble data loaders.\")\n",
        "print(f\"Each subset contains {len(ensemble_data_loaders[0].dataset)} samples.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdbd34fc"
      },
      "source": [
        "# NOTE: This cell is for training all 5 ensemble models. It takes a long time, so skip this cell if you want to load in our pre trained ensemble models instead.\n",
        "\n",
        "ensemble_models = []\n",
        "num_epochs_ensemble = 10\n",
        "\n",
        "print(f\"Initializing and training {N_ensemble} ensemble models...\")\n",
        "\n",
        "for i in range(N_ensemble):\n",
        "    print(f\"\\nTraining Ensemble Model {i+1}/{N_ensemble}\")\n",
        "\n",
        "    # re-initialize a new ResNet18 model instance for each ensemble member\n",
        "    model_ensemble = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "    # modify first conv layer for 32x32 images (CIFAR-10)\n",
        "    model_ensemble.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model_ensemble.maxpool = nn.Identity()  # remove maxpool for smaller images\n",
        "\n",
        "    # replace final layer for 10 classes\n",
        "    model_ensemble.fc = nn.Linear(model_ensemble.fc.in_features, 10)\n",
        "\n",
        "    # move the newly initialized model to the appropriate device\n",
        "    model_ensemble = model_ensemble.to(device)\n",
        "\n",
        "    # define a new CrossEntropyLoss criterion and a new Adam optimizer\n",
        "    criterion_ensemble = nn.CrossEntropyLoss()\n",
        "    optimizer_ensemble = optim.Adam(model_ensemble.parameters(), lr=1e-4)\n",
        "\n",
        "    # retrieve the corresponding DataLoader for this ensemble member\n",
        "    current_ensemble_loader = ensemble_data_loaders[i]\n",
        "\n",
        "    # train the current model\n",
        "    for epoch in range(num_epochs_ensemble):\n",
        "        train_loss, train_acc = train(model_ensemble, current_ensemble_loader, optimizer_ensemble, criterion_ensemble, device)\n",
        "        test_loss, test_acc = test(model_ensemble, test_loader, criterion_ensemble, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs_ensemble}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "    # f. Append the trained model to the ensemble_models list\n",
        "    ensemble_models.append(model_ensemble)\n",
        "\n",
        "print(\"\\nAll ensemble models trained successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3777a441"
      },
      "source": [
        "# NOTE: This cell is for loading in our pre trained ensemble models. Ensure the path for the models is correct in google drive.\n",
        "\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import os\n",
        "\n",
        "# mount google drive (if not already mounted)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# define the base path where ensemble models are saved\n",
        "load_base_path_ensemble = \"/content/drive/MyDrive/CS260D_Final_Project/ensemble_models/\"\n",
        "\n",
        "# initialize an empty list to store loaded ensemble models\n",
        "ensemble_models = []\n",
        "\n",
        "# define the number of ensemble models\n",
        "N_ensemble = 5 # this should match the N_ensemble used during training\n",
        "\n",
        "print(f\"Loading {N_ensemble} ensemble models...\")\n",
        "\n",
        "for i in range(N_ensemble):\n",
        "    load_path = os.path.join(load_base_path_ensemble, f\"model_ensemble_{i}.pth\")\n",
        "\n",
        "    # re-initialize the model architecture (must match the saved model)\n",
        "    model_member = models.resnet18(weights='IMAGENET1K_V1')\n",
        "    model_member.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    model_member.maxpool = nn.Identity()\n",
        "    model_member.fc = nn.Linear(model_member.fc.in_features, 10)\n",
        "\n",
        "    # move the model to the appropriate device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_member = model_member.to(device)\n",
        "\n",
        "    # load the saved state dictionary\n",
        "    if os.path.exists(load_path):\n",
        "        model_member.load_state_dict(torch.load(load_path, map_location=device))\n",
        "        model_member.eval() # set to evaluation mode after loading\n",
        "        ensemble_models.append(model_member)\n",
        "        print(f\"  Model {i+1} loaded from: {load_path}\")\n",
        "    else:\n",
        "        print(f\"  Warning: Model {i+1} not found at {load_path}. Skipping.\")\n",
        "\n",
        "print(f\"Successfully loaded {len(ensemble_models)} ensemble models.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3ca63e0"
      },
      "source": [
        "def ensemble_predict(images, ensemble_models, device):\n",
        "\n",
        "    # initialize an empty list to store the softmax probabilities from each model\n",
        "    all_model_probabilities = []\n",
        "\n",
        "    # iterate through each model in the ensemble_models list\n",
        "    for model in ensemble_models:\n",
        "\n",
        "        # set the model to evaluation mode\n",
        "        model.eval()\n",
        "        # move the input images to the specified device\n",
        "        images = images.to(device)\n",
        "\n",
        "        # use torch.no_grad() context manager for inference\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # get the raw outputs from the current model\n",
        "            outputs = model(images)\n",
        "            # apply torch.softmax to the outputs to get probabilities\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            # append these probabilities to the list\n",
        "            all_model_probabilities.append(probabilities)\n",
        "\n",
        "    # concatenate the collected probabilities into a single tensor\n",
        "    # the dimension for concatenation should be 0, creating a tensor of shape (N_ensemble, batch_size, num_classes)\n",
        "    all_model_probabilities_tensor = torch.stack(all_model_probabilities)\n",
        "\n",
        "    # compute the element-wise mean across the model dimension (dimension 0) to get the average probabilities\n",
        "    average_probabilities = torch.mean(all_model_probabilities_tensor, dim=0)\n",
        "\n",
        "    # determine the final predicted class by finding the index of the maximum value\n",
        "    final_prediction = torch.argmax(average_probabilities, dim=1)\n",
        "\n",
        "    return final_prediction\n",
        "\n",
        "print(\"Function ensemble_predict defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94d7e746"
      },
      "source": [
        "print(\"\\nEVALUATION OF TARGET IMAGE WITH ENSEMBLE DEFENDED MODEL\")\n",
        "print(f\"Original true and predicted class: {train_set.classes[target_true_label]}\")\n",
        "\n",
        "# move target image to device and add batch dimension for ensemble prediction\n",
        "target_image_on_device_batch = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "# get ensemble's prediction for the target image\n",
        "ensemble_predicted_idx_batch = ensemble_predict(target_image_on_device_batch, ensemble_models, device)\n",
        "ensemble_predicted_idx = ensemble_predicted_idx_batch.item()\n",
        "predicted_ensemble_class = train_set.classes[ensemble_predicted_idx]\n",
        "\n",
        "print(f\"Ensemble defended model's prediction: {predicted_ensemble_class}\")\n",
        "\n",
        "# to get probabilities from the ensemble for comparison, we need to average them explicitly\n",
        "all_model_probabilities_target = []\n",
        "for model in ensemble_models:\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(target_image_on_device_batch)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        all_model_probabilities_target.append(probabilities)\n",
        "ensemble_probabilities_target = torch.mean(torch.stack(all_model_probabilities_target), dim=0).squeeze(0)\n",
        "\n",
        "# get top 10 probabilities and classes for the ensemble model's prediction\n",
        "top10_probs_ensemble, top10_indices_ensemble = torch.topk(ensemble_probabilities_target, 10)\n",
        "print(\"Top 10 predicted probabilities and classes (ensemble defended model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top10_indices_ensemble[i].item()]\n",
        "    probability = top10_probs_ensemble[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# explicitly compare deer and dog probabilities across all models\n",
        "print(f\"\\nCOMPARISON (BASELINE VS POISONED VS LOSS OUTLIER DEFENDED VS ADAPTIVE BILEVEL DEFENDED VS ACTIVATION CLUSTERING DEFENDED VS ENSEMBLE DEFENDED)\")\n",
        "print(f\"Baseline model probability for deer: {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline model probability for dog: {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for deer: {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for dog: {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier defended model probability for deer: {probabilities_defended[deer_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier defended model probability for dog: {probabilities_defended[dog_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel defended model probability for deer: {probabilities_bilevel_defended_adaptive[deer_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel defended model probability for dog: {probabilities_bilevel_defended_adaptive[dog_idx].item():.4f}\")\n",
        "print(f\"Activation clustering defended model probability for deer: {probabilities_defended_activation_clustering[deer_idx].item():.4f}\")\n",
        "print(f\"Activation clustering defended model probability for dog: {probabilities_defended_activation_clustering[dog_idx].item():.4f}\")\n",
        "print(f\"Ensemble defended model probability for deer: {ensemble_probabilities_target[deer_idx].item():.4f}\")\n",
        "print(f\"Ensemble defended model probability for dog: {ensemble_probabilities_target[dog_idx].item():.4f}\")\n",
        "\n",
        "# summary of reclassification for ensemble\n",
        "if ensemble_predicted_idx == dog_idx:\n",
        "    print(f\"\\nThe ensemble defended model still misclassified the deer image as a dog.\")\n",
        "elif ensemble_predicted_idx == deer_idx:\n",
        "    print(f\"\\nThe ensemble defended model correctly classified the deer image as a deer.\")\n",
        "else:\n",
        "    print(f\"\\nThe ensemble defended model predicted the deer image as a {predicted_ensemble_class}.\")\n",
        "\n",
        "correct_ensemble = 0\n",
        "total_ensemble = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        predictions = ensemble_predict(images, ensemble_models, device)\n",
        "        total_ensemble += labels.size(0)\n",
        "        correct_ensemble += (predictions == labels).sum().item()\n",
        "\n",
        "test_acc_ensemble = correct_ensemble / total_ensemble\n",
        "print(f\"\\nTest accuracy of ensemble defended model: {test_acc_ensemble:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest test accuracy overall on the poisoned set, but it failed to re-classify the image correctly."
      ],
      "metadata": {
        "id": "o9JwaRiygqGB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8d81420"
      },
      "source": [
        "## Influence Based Data Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d16d047"
      },
      "source": [
        "import copy\n",
        "\n",
        "# copy of poisoned model\n",
        "model_for_influence = copy.deepcopy(model_poisoned)\n",
        "\n",
        "model_for_influence.eval()\n",
        "model_for_influence = model_for_influence.to(device)\n",
        "\n",
        "# loss function\n",
        "criterion_influence = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38d53004"
      },
      "source": [
        "def get_gradient_vector(model, image, label, criterion, device):\n",
        "    model.zero_grad()\n",
        "\n",
        "    # prepare a single batch and move to device\n",
        "    image_batch = image.unsqueeze(0).to(device)\n",
        "    label_batch = torch.tensor([label]).to(device)\n",
        "\n",
        "    # run model and compute loss\n",
        "    output = model(image_batch)\n",
        "    loss = criterion(output, label_batch)\n",
        "\n",
        "    # backprop\n",
        "    loss.backward()\n",
        "\n",
        "    # flatten and collect data\n",
        "    grad_vector = []\n",
        "    for param in model.parameters():\n",
        "        if param.grad is not None:\n",
        "            grad_vector.append(param.grad.view(-1))\n",
        "\n",
        "    return torch.cat(grad_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a17c570c"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# enable gradient calculation\n",
        "for param in model_for_influence.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# target misclassication set to dog\n",
        "target_misclassification_label = dog_idx\n",
        "\n",
        "print(f\"Calculating gradient for target image (true class: {train_set.classes[target_true_label]}, \"\n",
        "      f\"misclassified as: {train_set.classes[target_misclassification_label]})...\")\n",
        "\n",
        "# calculate gradient for the target image with dog label\n",
        "grad_target = get_gradient_vector(\n",
        "    model_for_influence, target_image, target_misclassification_label, criterion_influence, device\n",
        ")\n",
        "grad_target = grad_target.detach()\n",
        "\n",
        "# prepare samples for scoring\n",
        "influence_scores = []\n",
        "train_loader_no_shuffle = DataLoader(poisoned_train_set, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Calculating influence scores for each training sample...\")\n",
        "for i, (image, label) in enumerate(tqdm(train_loader_no_shuffle, desc=\"Calculating Influences\")):\n",
        "    # get gradient\n",
        "    grad_train_sample = get_gradient_vector(model_for_influence, image.squeeze(0), label.item(), criterion_influence, device)\n",
        "\n",
        "    # get dot product between target gradient and each sample gradient\n",
        "    influence = torch.dot(grad_target, grad_train_sample).item()\n",
        "    influence_scores.append((influence, i, label.item()))\n",
        "\n",
        "# sort in descending ordder\n",
        "influence_scores.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "print(f\"\\nTop 10 most influential samples (positive influence means contributing to misclassification):\")\n",
        "for j in range(10):\n",
        "    score, idx, original_label = influence_scores[j]\n",
        "    print(f\"  Rank {j+1}: Original Index {idx}, Original Label: {train_set.classes[original_label]}, Influence: {score:.4f}\")\n",
        "\n",
        "for param in model_for_influence.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"Influence scores calculated and ranked.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "917e077b"
      },
      "source": [
        "num_samples_to_remove = 250 # we poisoned 250 sammples eariler\n",
        "\n",
        "# get indices of samples we will prune\n",
        "indices_to_remove_influence = [idx for score, idx, _ in influence_scores[:num_samples_to_remove]]\n",
        "remove_indices_set_influence = set(indices_to_remove_influence)\n",
        "\n",
        "# get original indices from the poisoned set and decide which ones to keep\n",
        "all_original_indices = list(range(len(poisoned_train_set)))\n",
        "indices_to_keep_influence = [idx for idx in all_original_indices if idx not in remove_indices_set_influence]\n",
        "\n",
        "print(f\"Total samples in original poisoned_train_set: {len(poisoned_train_set)}\")\n",
        "print(f\"Number of samples identified as most influential/poisoned: {len(indices_to_remove_influence)}\")\n",
        "print(f\"Number of samples to keep for training: {len(indices_to_keep_influence)}\")\n",
        "\n",
        "# create subset from which samples to keep\n",
        "cleaned_train_set_influence = torch.utils.data.Subset(poisoned_train_set, indices_to_keep_influence)\n",
        "\n",
        "# dataloader for new subset\n",
        "cleaned_train_loader_influence = torch.utils.data.DataLoader(\n",
        "    cleaned_train_set_influence, batch_size=128, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"\\nSuccessfully created cleaned_train_set_influence with {len(cleaned_train_set_influence)} samples.\")\n",
        "print(f\"Successfully created cleaned_train_loader_influence with {len(cleaned_train_loader_influence.dataset)} samples and batch size {cleaned_train_loader_influence.batch_size}.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "070c4ada"
      },
      "source": [
        "# NOTE: This cell is for training our model after influence based data pruning. Skip this cell if you want to load in our pre trained model instead.\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "# start with fresh resnet18 to ensure no leftover poisioning weights\n",
        "model_defended_influence = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# set resnet18 parameters as in the beginning of notebook\n",
        "model_defended_influence.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended_influence.maxpool = nn.Identity()\n",
        "model_defended_influence.fc = nn.Linear(model_defended_influence.fc.in_features, 10)\n",
        "model_defended_influence = model_defended_influence.to(device)\n",
        "criterion_defended_influence = nn.CrossEntropyLoss()\n",
        "optimizer_defended_influence = optim.Adam(model_defended_influence.parameters(), lr=1e-4)\n",
        "\n",
        "num_epochs_defended_influence = 10\n",
        "\n",
        "print(f\"Training influence-based defended model for {num_epochs_defended_influence} epochs...\")\n",
        "\n",
        "for epoch in range(num_epochs_defended_influence):\n",
        "    train_loss, train_acc = train(\n",
        "        model_defended_influence,\n",
        "        cleaned_train_loader_influence,\n",
        "        optimizer_defended_influence,\n",
        "        criterion_defended_influence,\n",
        "        device\n",
        "    )\n",
        "    test_loss, test_acc = test(model_defended_influence, test_loader, criterion_defended_influence, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_defended_influence}  |  \"f\"Train Acc: {train_acc:.3f}  |  Test Acc: {test_acc:.3f}\")\n",
        "\n",
        "print(\"\\nInfluence-based defended model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: This cell is for loading our pre trained model that was trained after influence based data pruning. Ensure the model path in google drive is correct.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "load_path_defended_influence = \"/content/drive/MyDrive/CS260D_Final_Project/model_defended_influence.pth\"\n",
        "\n",
        "model_defended_influence = models.resnet18(weights='IMAGENET1K_V1')\n",
        "model_defended_influence.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "model_defended_influence.maxpool = nn.Identity()\n",
        "model_defended_influence.fc = nn.Linear(model_defended_influence.fc.in_features, 10)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_defended_influence = model_defended_influence.to(device)\n",
        "\n",
        "model_defended_influence.load_state_dict(torch.load(load_path_defended_influence, map_location=device))\n",
        "model_defended_influence.eval()\n",
        "\n",
        "criterion_defended_influence = nn.CrossEntropyLoss()\n",
        "\n",
        "print(f\"Influence function defended model loaded from: {load_path_defended_influence}\")"
      ],
      "metadata": {
        "id": "Or2RFNdQCYuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "100afee0"
      },
      "source": [
        "model_defended_influence.eval()\n",
        "\n",
        "# prepare target image\n",
        "target_image_on_device = target_image.to(device).unsqueeze(0)\n",
        "\n",
        "print(\"\\nEVALUATION OF TARGET IMAGE WITH INFLUENCE PRUNING DEFENDED MODEL\")\n",
        "print(f\"Original true and predicted class: {train_set.classes[target_true_label]}\")\n",
        "\n",
        "# run infrence\n",
        "with torch.no_grad():\n",
        "    outputs_defended_influence = model_defended_influence(target_image_on_device)\n",
        "    probabilities_defended_influence = torch.softmax(outputs_defended_influence, dim=1).squeeze(0)\n",
        "    _, predicted_defended_influence_idx = torch.max(probabilities_defended_influence, 0)\n",
        "\n",
        "predicted_defended_influence_class = train_set.classes[predicted_defended_influence_idx.item()]\n",
        "\n",
        "print(f\"Influence pruning defended model's prediction: {predicted_defended_influence_class}\")\n",
        "\n",
        "# top 10 probabilities and classes for the model prediction\n",
        "top10_probs_defended_influence, top10_indices_defended_influence = torch.topk(probabilities_defended_influence, 10)\n",
        "print(\"Top 10 predicted probabilities and classes (influence pruning defended model):\")\n",
        "for i in range(10):\n",
        "    class_name = train_set.classes[top10_indices_defended_influence[i].item()]\n",
        "    probability = top10_probs_defended_influence[i].item()\n",
        "    print(f\"  {class_name}: {probability:.4f}\")\n",
        "\n",
        "# compare deer and dog probabilities across previous models\n",
        "print(f\"\\nCOMPARISON (BASELINE VS POISONED VS LOSS OUTLIER DEFENDED VS ADAPTIVE BILEVEL DEFENDED VS ACTIVATION CLUSTERING DEFENDED VS ENSEMBLE DEFENDED VS INFLUENCE PRUNING DEFENDED)\")\n",
        "print(f\"Baseline model probability for deer: {target_probabilities[deer_idx].item():.4f}\")\n",
        "print(f\"Baseline model probability for dog: {target_probabilities[dog_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for deer: {probabilities_poisoned[deer_idx].item():.4f}\")\n",
        "print(f\"Poisoned model probability for dog: {probabilities_poisoned[dog_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier defended model probability for deer: {probabilities_defended[deer_idx].item():.4f}\")\n",
        "print(f\"Loss-outlier defended model probability for dog: {probabilities_defended[dog_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel defended model probability for deer: {probabilities_bilevel_defended_adaptive[deer_idx].item():.4f}\")\n",
        "print(f\"Adaptive bilevel defended model probability for dog: {probabilities_bilevel_defended_adaptive[dog_idx].item():.4f}\")\n",
        "print(f\"Activation clustering defended model probability for deer: {probabilities_defended_activation_clustering[deer_idx].item():.4f}\")\n",
        "print(f\"Activation clustering defended model probability for dog: {probabilities_defended_activation_clustering[dog_idx].item():.4f}\")\n",
        "print(f\"Ensemble defended model probability for deer: {ensemble_probabilities_target[deer_idx].item():.4f}\")\n",
        "print(f\"Ensemble defended model probability for dog: {ensemble_probabilities_target[dog_idx].item():.4f}\")\n",
        "print(f\"Influence pruning defended model probability for deer: {probabilities_defended_influence[deer_idx].item():.4f}\")\n",
        "print(f\"Influence pruning defended model probability for dog: {probabilities_defended_influence[dog_idx].item():.4f}\")\n",
        "\n",
        "if predicted_defended_influence_idx.item() == dog_idx:\n",
        "    print(f\"\\nThe influence pruning defended model still misclassified the deer image as a dog.\")\n",
        "elif predicted_defended_influence_idx.item() == deer_idx:\n",
        "    print(f\"\\nThe influence pruning defended model correctly classified the deer image as a deer.\")\n",
        "else:\n",
        "    print(f\"\\nThe influence pruning defended model predicted the deer image as a {predicted_defended_influence_class}.\")\n",
        "\n",
        "# overall test accuracy\n",
        "test_loss_defended_influence, test_acc_defended_influence = test(model_defended_influence, test_loader, criterion_defended_influence, device)\n",
        "print(f\"\\nTest accuracy of influence pruning defended model: {test_acc_defended_influence:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd333395"
      },
      "source": [
        "## Compare Results and Visualize\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae28fb26"
      },
      "source": [
        "deer_idx = train_set.classes.index('deer')\n",
        "dog_idx = train_set.classes.index('dog')\n",
        "\n",
        "baseline_deer_prob = target_probabilities[deer_idx].item()\n",
        "baseline_dog_prob = target_probabilities[dog_idx].item()\n",
        "\n",
        "poisoned_deer_prob = probabilities_poisoned[deer_idx].item()\n",
        "poisoned_dog_prob = probabilities_poisoned[dog_idx].item()\n",
        "\n",
        "loss_outlier_deer_prob = probabilities_defended[deer_idx].item()\n",
        "loss_outlier_dog_prob = probabilities_defended[dog_idx].item()\n",
        "\n",
        "bilevel_deer_prob = probabilities_bilevel_defended_adaptive[deer_idx].item()\n",
        "bilevel_dog_prob = probabilities_bilevel_defended_adaptive[dog_idx].item()\n",
        "\n",
        "activation_clustering_deer_prob = probabilities_defended_activation_clustering[deer_idx].item()\n",
        "activation_clustering_dog_prob = probabilities_defended_activation_clustering[dog_idx].item()\n",
        "\n",
        "ensemble_deer_prob = ensemble_probabilities_target[deer_idx].item()\n",
        "ensemble_dog_prob = ensemble_probabilities_target[dog_idx].item()\n",
        "\n",
        "influence_deer_prob = probabilities_defended_influence[deer_idx].item()\n",
        "influence_dog_prob = probabilities_defended_influence[dog_idx].item()\n",
        "\n",
        "print(f\"Baseline Deer Prob: {baseline_deer_prob:.4f}, Dog Prob: {baseline_dog_prob:.4f}\")\n",
        "print(f\"Poisoned Deer Prob: {poisoned_deer_prob:.4f}, Dog Prob: {poisoned_dog_prob:.4f}\")\n",
        "print(f\"Loss-Outlier Defended Deer Prob: {loss_outlier_deer_prob:.4f}, Dog Prob: {loss_outlier_dog_prob:.4f}\")\n",
        "print(f\"Adaptive Bilevel Defended Deer Prob: {bilevel_deer_prob:.4f}, Dog Prob: {bilevel_dog_prob:.4f}\")\n",
        "print(f\"Activation Clustering Defended Deer Prob: {activation_clustering_deer_prob:.4f}, Dog Prob: {activation_clustering_dog_prob:.4f}\")\n",
        "print(f\"Ensemble Defended Deer Prob: {ensemble_deer_prob:.4f}, Dog Prob: {ensemble_dog_prob:.4f}\")\n",
        "print(f\"Influence Pruning Defended Deer Prob: {influence_deer_prob:.4f}, Dog Prob: {influence_dog_prob:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c4a9763"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create lists for model names and their respective deer and dog probabilities\n",
        "models = [\n",
        "    \"Baseline\",\n",
        "    \"Poisoned\",\n",
        "    \"Loss-Outlier Defended\",\n",
        "    \"Adaptive Bilevel Defended\",\n",
        "    \"Activation Clustering Defended\",\n",
        "    \"Ensemble Defended\",\n",
        "    \"Influence Pruning Defended\"\n",
        "]\n",
        "\n",
        "deer_probs = [\n",
        "    baseline_deer_prob,\n",
        "    poisoned_deer_prob,\n",
        "    loss_outlier_deer_prob,\n",
        "    bilevel_deer_prob,\n",
        "    activation_clustering_deer_prob,\n",
        "    ensemble_deer_prob,\n",
        "    influence_deer_prob\n",
        "]\n",
        "\n",
        "dog_probs = [\n",
        "    baseline_dog_prob,\n",
        "    poisoned_dog_prob,\n",
        "    loss_outlier_dog_prob,\n",
        "    bilevel_dog_prob,\n",
        "    activation_clustering_dog_prob,\n",
        "    ensemble_dog_prob,\n",
        "    influence_dog_prob\n",
        "]\n",
        "\n",
        "# create a DataFrame for easy handling\n",
        "prob_df = pd.DataFrame({\n",
        "    'Model': models,\n",
        "    'Deer Probability': deer_probs,\n",
        "    'Dog Probability': dog_probs\n",
        "})\n",
        "\n",
        "print(prob_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f7f0e7f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# set up the figure size for better readability\n",
        "plt.figure(figsize=(14, 8))\n",
        "\n",
        "# define the bar width and positions\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(prob_df['Model']))\n",
        "\n",
        "# create the bars for 'Deer Probability'\n",
        "plt.bar(index, prob_df['Deer Probability'], bar_width, label='Deer Probability', color='skyblue')\n",
        "\n",
        "# create the bars for 'Dog Probability', slightly offset\n",
        "plt.bar(index + bar_width, prob_df['Dog Probability'], bar_width, label='Dog Probability', color='lightcoral')\n",
        "\n",
        "# add labels, title, and ticks\n",
        "plt.xlabel('Model', fontsize=12)\n",
        "plt.ylabel('Probability', fontsize=12)\n",
        "plt.title('Deer vs. Dog Probability for Target Image Across Models', fontsize=14)\n",
        "plt.xticks(index + bar_width / 2, prob_df['Model'], rotation=45, ha='right', fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylim(0, 1) # probabilities are between 0 and 1\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout() # adjust layout to prevent labels from overlapping\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"Bar chart visualizing deer and dog probabilities across models displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa8b94ea"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create a list named of model names\n",
        "model_names = [\n",
        "    'Baseline',\n",
        "    'Poisoned',\n",
        "    'Loss-Outlier Defended',\n",
        "    'Adaptive Bilevel Defended',\n",
        "    'Activation Clustering Defended',\n",
        "    'Ensemble Defended',\n",
        "    'Influence Pruning Defended'\n",
        "]\n",
        "\n",
        "# create a list named of test accuracies\n",
        "test_accuracies = [\n",
        "    test_acc,\n",
        "    test_acc_poisoned,\n",
        "    test_acc_defended,\n",
        "    test_acc_bilevel_defended_adaptive,\n",
        "    test_acc_defended_activation_clustering,\n",
        "    test_acc_ensemble,\n",
        "    test_acc_defended_influence\n",
        "]\n",
        "\n",
        "# create a Pandas DataFrame\n",
        "accuracy_df = pd.DataFrame({\n",
        "    'Model': model_names,\n",
        "    'Test Accuracy': test_accuracies\n",
        "})\n",
        "\n",
        "# print the DataFrame\n",
        "print(accuracy_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00ce73a2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# set up the figure size for better readability\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# define the bar width and positions\n",
        "bar_width = 0.6\n",
        "index = np.arange(len(accuracy_df['Model']))\n",
        "\n",
        "# create the bars for 'Test Accuracy'\n",
        "plt.bar(index, accuracy_df['Test Accuracy'], bar_width, color='dodgerblue')\n",
        "\n",
        "# add labels, title, and ticks\n",
        "plt.xlabel('Model', fontsize=12)\n",
        "plt.ylabel('Test Accuracy', fontsize=12)\n",
        "plt.title('Overall Test Accuracy Across Models', fontsize=14)\n",
        "plt.xticks(index, accuracy_df['Model'], rotation=45, ha='right', fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.ylim(0.8, 1) # accuracy is between 0.8 and 1\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout() # adjust layout to prevent labels from overlapping\n",
        "\n",
        "# display the plot\n",
        "plt.show()\n",
        "\n",
        "print(\"Bar chart visualizing overall test accuracies across models displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}